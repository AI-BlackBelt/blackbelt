{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A deep learning demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Jupyter notebook, live in your browser, with executable Python code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "b = 4*8\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running from Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/glouppe/blackbelt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd blackbelt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a pre-trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image = load_img(\"data/dogs-vs-cats/train/dogs/dog.1106.jpg\", target_size=(224, 224))\n",
    "#image = load_img(\"data/dogs-vs-cats/train/cats/cat.1553.jpg\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "\n",
    "# retrieve the most likely result\n",
    "label = label[0][0]\n",
    "\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a small convolutional network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of dogs and cats\n",
    "train_data_dir = \"data/dogs-vs-cats/train\"\n",
    "validation_data_dir = \"data/dogs-vs-cats/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l \"data/dogs-vs-cats/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l \"data/dogs-vs-cats/train/dogs\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data iterators\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_width, img_height = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional network\n",
    "from keras.models import Model \n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "h = Conv2D(32, (3, 3), activation=\"relu\")(inputs)\n",
    "h = MaxPooling2D(pool_size=(2, 2))(h)\n",
    "h = Conv2D(32, (3, 3), activation=\"relu\")(h)\n",
    "h = MaxPooling2D(pool_size=(2, 2))(h)\n",
    "h = Conv2D(32, (3, 3), activation=\"relu\")(h)\n",
    "h = MaxPooling2D(pool_size=(2, 2))(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(64, activation=\"relu\")(h)\n",
    "h = Dropout(0.5)(h)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(h)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 2000\n",
    "epochs = 1\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final accuracy at 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediction 1\n",
    "img_path = \"data/dogs-vs-cats/validation/cats/cat.2798.jpg\"\n",
    "image = load_img(img_path, target_size=(img_width, img_height))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "model.predict(image)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediction 2\n",
    "img_path = \"data/dogs-vs-cats/validation/dogs/dog.2774.jpg\"\n",
    "image = load_img(img_path, target_size=(img_width, img_height))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "model.predict(image)[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the top layer of a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# location of dogs and cats\n",
    "train_data_dir = \"data/dogs-vs-cats/train\"\n",
    "validation_data_dir = \"data/dogs-vs-cats/validation\"\n",
    "\n",
    "# data iterators\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_width, img_height = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "def preprocess_input_vgg(x):\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    return X[0]\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input_vgg,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vgg16 and fine-tune its top layer\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model \n",
    "\n",
    "base_model = VGG16(weights=\"imagenet\")\n",
    "h = base_model.get_layer(\"fc2\").output\n",
    "predictions = Dense(1, activation=\"sigmoid\", name=\"predictions\")(h)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name in [\"predictions\"]:\n",
    "        continue\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 2000\n",
    "epochs = 1\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final accuracy at 98%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediction 1\n",
    "img_path = \"data/dogs-vs-cats/validation/cats/cat.2010.jpg\"\n",
    "image = load_img(img_path, target_size=(img_width, img_height))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "model.predict(image)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediction 2\n",
    "img_path = \"data/dogs-vs-cats/validation/dogs/dog.2012.jpg\"\n",
    "image = load_img(img_path, target_size=(img_width, img_height))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "model.predict(image)[0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
